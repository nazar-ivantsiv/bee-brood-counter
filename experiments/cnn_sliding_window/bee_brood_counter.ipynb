{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "import os\nimport sys\n\nfrom time import sleep\nfrom time import time\nfrom random import randint\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nfrom sklearn import svm\nfrom sklearn.utils import shuffle\n\nNUM_CHANNELS = 3 # RGB\nIMG_SIZE = (64, 64) # Size of image\nPIXEL_DEPTH = 255.0  # Number of levels per pixel.\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {keras.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset routines ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_vec(img):\n",
    "    \"\"\"Resize an 'img' to correct size and make a vector ((60, 60, 3) => (64, 64, 3))\"\"\"\n",
    "    if img.shape[:2] != IMG_SIZE:\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "    return normalize(img.reshape(1, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS))\n",
    "\n",
    "def load_dataset(path, dataset_size=-1, downsample=False):\n",
    "    \"\"\"Loads samples from image files (e.g '001.png').\n",
    "    Args:\n",
    "        path -- path to the images(samples) (default size: 60px X 60px)\n",
    "        dataset_size -- number of samples to read\n",
    "        downsample -- downsamples input sample(img) if True\n",
    "    Returns:\n",
    "        images -- array (n, 60, 60, 1) of sample vectors as rows\n",
    "    \"\"\"\n",
    "    image_files = os.listdir(path)[:dataset_size]\n",
    "    # Init 'images' array as samples X features matrix\n",
    "    images = np.ndarray(shape=(len(image_files), IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS), \n",
    "                        dtype=np.float32)\n",
    "    image_idx = 0\n",
    "    for filename in image_files:\n",
    "        if NUM_CHANNELS == 3:\n",
    "            color_mode = cv2.IMREAD_COLOR\n",
    "        else:\n",
    "            color_mode = cv2.IMREAD_GRAYSCALE\n",
    "        img = cv2.imread(os.path.join(path, filename), color_mode)\n",
    "        if downsample:\n",
    "            # Downsample image (scale down by 50%)\n",
    "            img = cv2.pyrDown(img)\n",
    "        if img.shape[0] / img.shape[1] != IMG_SIZE[0] / IMG_SIZE[1]:\n",
    "            continue\n",
    "        # Convert img matrix to proper format vector (n, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS)\n",
    "        # Normalize (mean=0, stdev~=0.5)\n",
    "        images[image_idx, :] = make_feature_vec(img)\n",
    "        image_idx += 1\n",
    "    return images\n",
    "\n",
    "def label_dataset(pos_data, neg_data):\n",
    "    \"\"\"Prepare dataset. Combime pos and neg examples, label it & shuffle it.\n",
    "    Args:\n",
    "        pos_data -- array of positive samples\n",
    "        neg_data -- array of negative samples\n",
    "    Returns:\n",
    "        dataset -- samples array\n",
    "        labels -- labels vec\n",
    "    \"\"\"\n",
    "    num_pos_samples = pos_data.shape[0]\n",
    "    num_neg_samples = neg_data.shape[0] \n",
    "    num_total = num_pos_samples + num_neg_samples\n",
    "    dataset = np.vstack((pos_data, neg_data[:num_neg_samples])).astype(np.float32)\n",
    "    \n",
    "    # Label as 1-hot encoding \n",
    "    # ex. np.array([1, 0], dtype=np.float32) -- positive\n",
    "    # ex. np.array([0, 1], dtype=np.float32) -- negative\n",
    "    \n",
    "    num_classes = 2 # pos, neg\n",
    "    labels = np.ndarray(shape=(num_total, num_classes), dtype=np.float32)\n",
    "    labels[:num_pos_samples] = np.array([1, 0]) # positive\n",
    "    labels[num_pos_samples:] = np.array([0, 1]) # negative\n",
    "    \n",
    "    # Shuffle\n",
    "    return shuffle(dataset, labels, random_state=0)\n",
    "\n",
    "def normalize(img):\n",
    "    \"\"\"Normalize to have approximately zero mean and standard deviation ~0.5 \n",
    "    to make training easier down the road. \n",
    "    \"\"\"\n",
    "    mean = PIXEL_DEPTH / 2\n",
    "    return (img - mean) / PIXEL_DEPTH\n",
    "\n",
    "def preview(sample_vec):\n",
    "    %matplotlib inline\n",
    "    #mpld3.enable_notebook()\n",
    "    plt.imshow(sample_vec.reshape(IMG_SIZE))\n",
    "    \n",
    "def preview_random_examples(pos_data, neg_data):\n",
    "    %matplotlib inline\n",
    "    #mpld3.enable_notebook()\n",
    "    plt.figure(1)\n",
    "    pos_idx = randint(1, len(pos_data))\n",
    "    plt.title('POSITIVE (ex. #{})'.format(pos_idx))\n",
    "    plt.imshow(pos_data[pos_idx].reshape(IMG_SIZE + (NUM_CHANNELS, )))\n",
    "\n",
    "    plt.figure(2)\n",
    "    neg_idx = randint(1, len(neg_data))\n",
    "    plt.title('NEGATIVE (ex.#{})'.format(neg_idx))\n",
    "    plt.imshow(neg_data[neg_idx].reshape(IMG_SIZE + (NUM_CHANNELS, )))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load positive and negative examples from files into feature vectors ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_path = './dataset/positive/'\n",
    "neg_path = './dataset/negative/'\n",
    "pos_data = load_dataset(path=pos_path)\n",
    "neg_data = load_dataset(path=neg_path) #dataset_size=700)\n",
    "dataset, labels = label_dataset(pos_data, neg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "print(f'Number of POSITIVE samples: {len(pos_data)}\\n')\nprint(f'Number of NEGATIVE samples: {len(neg_data)}\\n')\npreview_random_examples(pos_data, neg_data)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt data into training, validation and test sets (60%, 20%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (2004, 64, 64, 3), (2004, 2))\n",
      "('Validation set', (668, 64, 64, 3), (668, 2))\n",
      "('Test set', (669, 64, 64, 3), (669, 2))\n"
     ]
    }
   ],
   "source": [
    "idx_train = int(dataset.shape[0] * 0.6)\n",
    "idx_cv = idx_train + int(dataset.shape[0] * 0.2)\n",
    "train_dataset = dataset[:idx_train]\n",
    "train_labels = labels[:idx_train]\n",
    "valid_dataset = dataset[idx_train:idx_cv]\n",
    "valid_labels = labels[idx_train:idx_cv]\n",
    "test_dataset = dataset[idx_cv:]\n",
    "test_labels = labels[idx_cv:]\n",
    "\n",
    "del dataset\n",
    "del labels\n",
    "\n",
    "#print('No samples missed during spliting: {}'.format(len(labels) == len(train_labels) + len(valid_labels) + len(test_labels)))\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Convolutional Neural Network ###\n",
    "Create CNN with custom architecture.\n",
    "- CONV1\n",
    "- RELU1\n",
    "- POOL1\n",
    "- CONV2\n",
    "- RELU2\n",
    "- POOL2\n",
    "- FC1\n",
    "- RELU3\n",
    "- FC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "### ConvNet with max pooling using Keras API\n\nbatch_size = 16\npatch_size = 5\ndepth = 16\nnum_hidden = 64\n\nlog_dir = './log'\nnum_labels = 2\n\n# Build the model using Keras functional API\ndef create_model():\n    \"\"\"Create the CNN model using Keras.\"\"\"\n    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS))\n    \n    # Layer 1: Conv + ReLU + MaxPool\n    x = keras.layers.Conv2D(filters=depth, kernel_size=patch_size, \n                            padding='same', activation='relu',\n                            kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1))(inputs)\n    x = keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same')(x)\n    \n    # Layer 2: Conv + ReLU + MaxPool\n    x = keras.layers.Conv2D(filters=depth, kernel_size=patch_size,\n                            padding='same', activation='relu',\n                            kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1),\n                            bias_initializer=keras.initializers.Constant(1.0))(x)\n    x = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n    \n    # Flatten\n    x = keras.layers.Flatten()(x)\n    \n    # Layer 3: Fully Connected + ReLU\n    x = keras.layers.Dense(num_hidden, activation='relu',\n                          kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1),\n                          bias_initializer=keras.initializers.Constant(1.0))(x)\n    \n    # Layer 4: Output layer\n    outputs = keras.layers.Dense(num_labels, activation='softmax',\n                                kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.1),\n                                bias_initializer=keras.initializers.Constant(1.0))(x)\n    \n    model = keras.Model(inputs=inputs, outputs=outputs, name='bee_brood_cnn')\n    \n    # Compile the model with optimizer and loss\n    # Using exponential decay learning rate schedule\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=0.005,\n        decay_steps=100,\n        decay_rate=0.96,\n        staircase=True\n    )\n    \n    optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# Create the model\nmodel = create_model()\n\n# Print model summary\nmodel.summary()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip this step and go to 'Restore saved model.' if you have your model saved. ###\n",
    "### =================================================== ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN  ###\n",
    "Train & save trained model to file './models/model_[accuracy].ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "num_steps = 1001\nnum_fetch_results = 50\n\n# Calculate number of epochs based on num_steps and dataset size\nsteps_per_epoch = train_labels.shape[0] // batch_size\nnum_epochs = (num_steps * batch_size) // train_labels.shape[0]\n\nprint(f'Training for {num_epochs} epochs ({num_steps} steps total)')\nprint(f'Steps per epoch: {steps_per_epoch}')\n\n# Create model\nmodel = create_model()\n\n# Train the model\nhistory = model.fit(\n    train_dataset, train_labels,\n    batch_size=batch_size,\n    epochs=num_epochs,\n    validation_data=(valid_dataset, valid_labels),\n    verbose=1\n)\n\n# Evaluate on test set\ntest_loss, test_accuracy = model.evaluate(test_dataset, test_labels, verbose=0)\nprint(f'\\nTest accuracy: {test_accuracy * 100:.1f}%')\n\n# Save the model\nmodel_filename = f\"model_{test_accuracy * 100:.2f}.keras\"\nmodel_save_path = os.path.join(\"./models/\", model_filename)\nos.makedirs(\"./models/\", exist_ok=True)\nmodel.save(model_save_path)\nprint(f\"Model saved in file: {model_save_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training curves ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "%matplotlib inline\n\n# Plot training and validation accuracy\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], '-o', label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], '-o', label='Training Loss')\nplt.plot(history.history['val_loss'], '-o', label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================================\n",
    "# Predict on unknown data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect capped brood cells on WHOLE image ###\n",
    "Use classifier on each single sample subimage, acquired with sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image to detect on.\n",
    "FILENAME = '003.png'\n",
    "PATH = '/home/chip/Dropbox/LITS/ML-003/dataset/processed_dataset/prespective_correction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore saved model.\n",
    "Change the 'tf_model_filename' to your saved model filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "tf_model_filename = 'model_95.98.keras'  # Model name file to restore (use .keras extension for TF 2.x)\ntf_model_path = os.path.join('./models/', tf_model_filename)\n\nPRED_THRESHOLD = 0.90  # Prediction threshold"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select a single CELL with a bounding box.\n",
    "<img src=\"how_to_select.png\">\n",
    "### (Use 's' key to save measurements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": "import bee_frame\nfrom nms import non_max_suppression_fast\n\nframe = bee_frame.BeeFrame()\nframe.load_image(PATH, FILENAME)\n\n### PRE-PROCESSING ###\n# Normalize histogram and smooth img.\nframe.image.hitogram_normalization()\nframe.image.blur()\n######################\n\n\n### PRESS 'S' key to save measurements. ###\nframe.get_cell_size()\n#frame.step_size = 10\n#frame.cell_size = 55\nprint('cell size: {}\\n'\n      'step size: {}'.format(frame.cell_size, frame.step_size))\n\n# Create sliding window generator.\nsamples_gen = frame.sliding_window()\nboxes_list = []  # Detected bounding boxes coordinates.\n\n#### Load the Keras model and use it for prediction. ###\n# Load the model\nif os.path.exists(tf_model_path):\n    model = keras.models.load_model(tf_model_path)\n    print(\"Model loaded from:\", tf_model_path)\nelse:\n    print(f\"Model file not found: {tf_model_path}\")\n    print(\"Please train a model first or update the model filename.\")\n    raise FileNotFoundError(f\"Model not found: {tf_model_path}\")\n\n# Iterate through all the samples\nstart = time()\nfor x, y, window in samples_gen:\n    # Prepare the sample for prediction\n    sample = make_feature_vec(window)\n    \n    # Make prediction\n    prediction = model.predict(sample, verbose=0)\n    \n    # Check if prediction exceeds threshold (first element is positive class probability)\n    if prediction[0][0] > PRED_THRESHOLD:\n        end_x = x + frame.cell_size\n        end_y = y + frame.cell_size\n        boxes_list.append([x, y, end_x, end_y])\n\nprint('elapsed: {:0.2f}'.format(time() - start))\n\n# Use NMS on detection results, to suppress duplicates in detection.\nboxes_np = np.array(boxes_list)\nif len(boxes_np) > 0:\n    boxes_np_nms = non_max_suppression_fast(boxes_np, 0.3)\nelse:\n    boxes_np_nms = boxes_np\n############################"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capped brood cells detected: 1365\n"
     ]
    }
   ],
   "source": [
    "preview_img = frame.image._img.copy()\n",
    "for box_coordinates in boxes_np_nms:\n",
    "        frame.image.draw_circle(box_coordinates, preview_img)\n",
    "\n",
    "cv2.namedWindow(frame.WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "frame.preview(preview_img)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('Capped brood cells detected: {}'.format(boxes_np_nms.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}