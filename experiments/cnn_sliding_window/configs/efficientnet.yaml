# EfficientNetB0 Transfer Learning Configuration
# Better accuracy than MobileNetV2, still relatively lightweight

data:
  dataset_path: "./dataset"
  positive_subdir: "positive"
  negative_subdir: "negative"
  img_size: [64, 64, 3]
  train_split: 0.6
  val_split: 0.2
  test_split: 0.2
  seed: 42

augmentation:
  enabled: true
  rotation_factor: 1.0
  flip_mode: "horizontal_and_vertical"
  zoom_range: [-0.1, 0.1]
  brightness_factor: 0.2
  contrast_factor: 0.2
  noise_stddev: 0.01

model:
  model_type: "efficientnet_b0"
  input_shape: [64, 64, 3]
  num_classes: 2
  freeze_base: true
  base_trainable: false
  global_pooling: "avg"
  dense_units: [256, 128]  # Slightly larger head
  dropout_rates: [0.4, 0.3, 0.2]

training:
  batch_size: 32
  epochs: 60
  learning_rate: 0.001
  optimizer: "adam"

  # Learning rate schedule
  lr_decay_enabled: true
  lr_decay_rate: 0.94
  lr_decay_steps: 50

  # Class imbalance handling
  use_class_weights: true
  class_weight_ratio: 4.3

  # Regularization
  l2_reg: 1e-4
  label_smoothing: 0.1

  # Early stopping
  early_stopping_patience: 15
  early_stopping_monitor: "val_f1_score"
  early_stopping_mode: "max"

  # Model checkpoint
  save_best_only: true
  checkpoint_monitor: "val_f1_score"
  checkpoint_mode: "max"

  # Two-stage training
  stage1_epochs: 20
  stage1_lr: 1e-3
  stage2_epochs: 40
  stage2_lr: 5e-6  # Lower for EfficientNet

cross_validation:
  enabled: false
  n_splits: 5
  shuffle: true
  stratified: true

experiment:
  tracking_uri: "./experiments"
  experiment_name: "bee_brood_counter"
  run_name: "efficientnet_b0_transfer"
  log_models: true
  log_artifacts: true

# Global settings
gpu_id: 0
mixed_precision: true
verbose: 1
